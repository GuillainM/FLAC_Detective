# Plan d'Optimisation Technique - FLAC Detective

## ğŸ“Š Analyse des Goulots d'Ã‰tranglement

### ProblÃ¨mes IdentifiÃ©s

#### 1. **Lectures Multiples de Fichiers** (Impact: ğŸ”´ CRITIQUE)
- `analyze_spectrum()`: Lit 3 segments du fichier (dÃ©but, milieu, fin)
- `analyze_segment_consistency()`: Lit 2 Ã  5 segments supplÃ©mentaires
- `detect_vinyl_noise()`: Relit le fichier complet
- `analyze_audio_quality()`: Relit le fichier complet
- **Total**: Jusqu'Ã  **10+ lectures** du mÃªme fichier!

#### 2. **Calculs FFT Redondants** (Impact: ğŸŸ  Ã‰LEVÃ‰)
- Chaque segment analysÃ© recalcule sa FFT
- Pas de rÃ©utilisation des spectres dÃ©jÃ  calculÃ©s
- FFT sur 30 secondes d'audio = ~1.3M samples = coÃ»teux

#### 3. **Conversions Mono RÃ©pÃ©tÃ©es** (Impact: ğŸŸ¡ MOYEN)
- Chaque fonction convertit stÃ©rÃ©o â†’ mono indÃ©pendamment
- Pas de cache de la version mono

#### 4. **Windowing RÃ©pÃ©tÃ©** (Impact: ğŸŸ¡ MOYEN)
- FenÃªtre de Hann recalculÃ©e Ã  chaque analyse
- Peut Ãªtre prÃ©calculÃ©e et rÃ©utilisÃ©e

---

## ğŸ¯ Plan d'Optimisation en 4 Phases

### **Phase 1: Optimisation du Cache de Fichiers** âš¡ (Gain estimÃ©: 60-70%)

#### ProblÃ¨me
Le systÃ¨me de cache existe mais n'est pas utilisÃ© partout.

#### Solution
```python
# 1. Utiliser AudioCache systÃ©matiquement
# Au lieu de:
data, sr = sf.read(filepath, start=start, frames=frames)

# Utiliser:
from .audio_cache import AudioCache
cache = AudioCache(filepath)
data, sr = cache.get_segment(start, frames)
```

#### Fichiers Ã  Modifier
1. âœ… `src/flac_detective/analysis/spectrum.py`
   - `analyze_spectrum()`: Utiliser cache pour les 3 segments
   - `analyze_segment_consistency()`: Utiliser cache pour les 2-5 segments

2. âœ… `src/flac_detective/analysis/new_scoring/silence.py`
   - `detect_vinyl_noise()`: Utiliser cache au lieu de `sf.read()`

3. âœ… `src/flac_detective/analysis/quality.py`
   - `AudioQualityAnalyzer.analyze()`: Utiliser cache

#### Impact EstimÃ©
- **Temps de lecture fichier**: -80% (1 lecture au lieu de 10)
- **Temps total**: -60% Ã  -70%

---

### **Phase 2: Pool de FenÃªtres PrÃ©calculÃ©es** ğŸ”§ (Gain estimÃ©: 5-10%)

#### ProblÃ¨me
```python
# RecalculÃ© Ã  chaque fois:
window = signal.windows.hann(len(data))
```

#### Solution
```python
# CrÃ©er un cache de fenÃªtres
_window_cache = {}

def get_hann_window(size: int) -> np.ndarray:
    """Get cached Hann window."""
    if size not in _window_cache:
        _window_cache[size] = signal.windows.hann(size)
    return _window_cache[size]
```

#### Fichiers Ã  Modifier
1. `src/flac_detective/analysis/spectrum.py`
2. `src/flac_detective/analysis/new_scoring/silence_utils.py`

#### Impact EstimÃ©
- **Temps de windowing**: -90%
- **Temps total**: -5% Ã  -10%

---

### **Phase 3: Optimisation FFT avec NumPy** ğŸš€ (Gain estimÃ©: 10-15%)

#### ProblÃ¨me
FFT calculÃ©e segment par segment sans optimisation.

#### Solution
```python
# 1. Utiliser scipy.fft.rfft avec workers=-1 (parallÃ©lisation)
from scipy.fft import rfft, rfftfreq, set_workers

# Au dÃ©but du programme:
set_workers(-1)  # Utilise tous les CPU disponibles

# 2. PrÃ©-allouer les arrays pour Ã©viter allocations mÃ©moire
def analyze_spectrum_optimized(data, samplerate):
    n = len(data)
    # PrÃ©-allocation
    fft_vals = np.empty(n // 2 + 1, dtype=np.complex128)
    magnitude = np.empty(n // 2 + 1, dtype=np.float64)
    
    # FFT avec plan optimisÃ©
    fft_vals = rfft(data, workers=-1)
    np.abs(fft_vals, out=magnitude)
    
    return magnitude
```

#### Impact EstimÃ©
- **Temps FFT**: -15% Ã  -20%
- **Temps total**: -10% Ã  -15%

---

### **Phase 4: Analyse Progressive Intelligente** ğŸ§  (Gain estimÃ©: 20-30%)

#### ProblÃ¨me
Certaines analyses sont lancÃ©es mÃªme si inutiles.

#### Solution: Short-Circuit Intelligent

```python
# 1. Dans new_calculate_score(), ajouter des courts-circuits:

def _apply_scoring_rules(context: ScoringContext) -> Tuple[int, List[str]]:
    # ... existing code ...
    
    # SHORT-CIRCUIT 1: Si score >= 86 aprÃ¨s R1+R2+R3
    if context.current_score >= 86:
        logger.info("âš¡ FAKE_CERTAIN dÃ©tectÃ© - Skip R7, R9, R10")
        return context.current_score, context.reasons
    
    # SHORT-CIRCUIT 2: Si score < 0 et pas de MP3 dÃ©tectÃ©
    if context.current_score < 0 and context.mp3_bitrate_detected is None:
        logger.info("âš¡ AUTHENTIC Ã©vident - Skip R7, R9, R10")
        return context.current_score, context.reasons
    
    # Continuer avec R7, R9, R10 seulement si nÃ©cessaire
```

#### Impact EstimÃ©
- **Fichiers Ã©vidents (60%)**: -40% temps (skip R7, R9, R10)
- **Temps total moyen**: -20% Ã  -30%

---

## ğŸ“ˆ RÃ©sumÃ© des Gains EstimÃ©s

| Phase | Optimisation | Gain Temps | DifficultÃ© | PrioritÃ© |
|-------|--------------|------------|------------|----------|
| **1** | Cache Fichiers | **60-70%** | ğŸŸ¢ Facile | â­â­â­â­â­ |
| **2** | Pool FenÃªtres | 5-10% | ğŸŸ¢ Facile | â­â­â­ |
| **3** | FFT OptimisÃ©e | 10-15% | ğŸŸ¡ Moyen | â­â­â­â­ |
| **4** | Short-Circuits | 20-30% | ğŸŸ¡ Moyen | â­â­â­â­ |
| **TOTAL** | **CumulÃ©** | **75-85%** | - | - |

### Temps de Traitement EstimÃ© (pour 1000 fichiers)

| ScÃ©nario | Avant | AprÃ¨s Phase 1 | AprÃ¨s Toutes Phases |
|----------|-------|---------------|---------------------|
| **Temps/fichier** | 3.0s | 1.0s | 0.5s |
| **Total 1000 fichiers** | 50 min | 17 min | **8 min** |
| **Gain** | - | **-66%** | **-84%** |

---

## ğŸ› ï¸ Plan d'ImplÃ©mentation RecommandÃ©

### Semaine 1: Phase 1 (PrioritÃ© MAXIMALE)
**Objectif**: ImplÃ©menter le cache systÃ©matique
- Jour 1-2: Modifier `spectrum.py` pour utiliser `AudioCache`
- Jour 3: Modifier `silence.py` pour utiliser `AudioCache`
- Jour 4: Modifier `quality.py` pour utiliser `AudioCache`
- Jour 5: Tests et validation

**Gain attendu**: **60-70% de rÃ©duction du temps**

### Semaine 2: Phases 2 + 3
**Objectif**: Optimisations FFT et windowing
- Jour 1-2: ImplÃ©menter pool de fenÃªtres
- Jour 3-4: Optimiser FFT avec parallÃ©lisation
- Jour 5: Tests et validation

**Gain attendu**: **+15-25% supplÃ©mentaire**

### Semaine 3: Phase 4
**Objectif**: Short-circuits intelligents
- Jour 1-3: ImplÃ©menter logique de court-circuit
- Jour 4-5: Tests et validation

**Gain attendu**: **+20-30% supplÃ©mentaire**

---

## ğŸ” Optimisations SupplÃ©mentaires (Optionnel)

### A. Utiliser `numba` pour les Boucles Critiques
```python
from numba import jit

@jit(nopython=True)
def detect_cutoff_fast(frequencies, magnitude_db):
    # Version compilÃ©e JIT = 10x plus rapide
    ...
```
**Gain**: +10-20% sur les calculs intensifs

### B. Batch Processing avec `multiprocessing`
```python
# Analyser plusieurs fichiers en parallÃ¨le
from multiprocessing import Pool

with Pool(processes=4) as pool:
    results = pool.map(analyze_file, file_list)
```
**Gain**: 3-4x sur machines multi-core

### C. Utiliser `mmap` pour Gros Fichiers
```python
import mmap

# Pour fichiers > 100 MB
with open(filepath, 'rb') as f:
    with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mmapped:
        # Lecture ultra-rapide
        ...
```
**Gain**: +30-40% sur gros fichiers

---

## âœ… Checklist de Validation

AprÃ¨s chaque phase:
- [ ] Tests unitaires passent
- [ ] RÃ©sultats identiques Ã  la version prÃ©cÃ©dente
- [ ] Mesure du temps d'exÃ©cution (avant/aprÃ¨s)
- [ ] Profiling mÃ©moire (pas d'augmentation)
- [ ] Tests sur 100 fichiers variÃ©s

---

## ğŸ“Š MÃ©triques Ã  Suivre

```python
# Ajouter un systÃ¨me de profiling
import time
import functools

def profile(func):
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        start = time.perf_counter()
        result = func(*args, **kwargs)
        end = time.perf_counter()
        logger.info(f"â±ï¸ {func.__name__}: {end-start:.3f}s")
        return result
    return wrapper

# Utiliser sur fonctions critiques:
@profile
def analyze_spectrum(filepath, sample_duration):
    ...
```

---

## ğŸ¯ Objectif Final

**RÃ©duire le temps de traitement de 75-85% sans perte de qualitÃ©**

- âœ… MÃªme prÃ©cision de dÃ©tection
- âœ… MÃªme qualitÃ© de rÃ©sultats
- âœ… Code plus maintenable
- âœ… Utilisation mÃ©moire contrÃ´lÃ©e

**Temps cible**: **< 0.5 seconde par fichier** (vs 3 secondes actuellement)
